# Виртуальный куб Qubisio - вместо OLAP


##  Абстрактно

_Когда делаешь наоборот и получаешь то же ..._

Имея задачу аналитической (вычислительной/агрегирующей) обработки данных приходится искать копромисс между отзывчивостью, скоростью и удобством. 

Одни системы хорошо индексируют и находят, другие быстро считают и агрегируют данные, третьи просты. Где-то приходится организовывать предварительную загрузку и индексирование данных со всеми сопутствующими трудностями, а где-то пользователю предоставляется абстракция его модели исходных и агрегированных данных поверх встроенных или внешних физических хранилищ и баз данных, используемых непосредственно во время вычислений. В любом случае, пользователь, от программиста до аналитика, должен проделать относительно большую работу, начиная с подготовки сырых данных и составления запросов, модели вычислений, заканчивая визуальным оформлением результата на виджетах, конечно же "Sexy" - красивых, отзывчивых и понятных, - иначе в конце вся проделанная работа пойдет насмарку. И часто, как назло, пройдя муки выбора решения, мы замечаем, как простая и понятная на первый взгляд задача вырастает в жуткого монстра, с которым имеющимися средставами бороться бесполезно, и надо срочно что-то изобретать - велосипед, но "с блэкджеком и шлюхами". Наш велосипед поехал, даже неплохо объезжает кочки и справляется с препятствиями, о которых раньше можно было только гадать. 

_Простая задача должна решаться просто, а сложная - тоже просто, но дольше ..._

Начиная создавать систему малыми силами, мы пошли от простого к сложному. Создавая конструктор, мы были внутренне убеждены, что мы хорошо понимаем цель системы, борясь одновременно с желанием не делать лишнего и противоположным желанием автоматизировать всё и вся, для всего создавая фреймворк. Тем более, что один замечательный фреймворк был уже готов и даже обкатан в продакшене (**jsBeans** - наша клиент-серверная платформа, которая очень хорошо вписывается в лежащие перед нами задачи). Итак, мы приступили к разработке очередной системы обработки данных, которая выросла и сейчас представляет из себя одновременно и самодостаточный продукт - конструктор, и платформу разработки целого класса систем обработки данных - **Qubisio**. 

Ниже будет описана одна сторона оригинального внутреннего устройства этой системы - вычислительная обработка для интерактивной визуализации данных. 

## Введение - куб, срез, измерение

$$$ Тут надо другое введение в ключевой принцип

Главный принцип - имея наборы несвязанных данных, включая разнородные внешние БД, сформировать многомерную модель из связанных между собой элементов исходных данных и результатов их аналитической обработки для визуализации на динамических дашбордах и взаимосвязанных виджетах.




![mosedu-dashboard](mosedu-dashboard.png)_Пример дашборда_

Такая модель в нашей системе называется "Куб" и буквально представляет собой абстрактную коллекцию изменяемых наборов данных, называемых "Срез", связанных между собой общими выходными (отображаемыми) полями/столбцами или внутренними полями, называемыми "Измерения" и используемыми для фильтрации и связывания срезов между собой. 




![mosedu-cube](mosedu-cube.png)

_Пример модели данных куба_

Если выходное поле среза одновременно является измерением в другом срезе, имеет такое же название, то значения этого поля воспринимаются системой как "факты" (если бы мы говорили про OLAP), заданные в форме глобального фильтра, изменяющего исходные наборы данных во время вычислений и агрегации.  Как следствие возникает динамика взаимодействия виджетов, при которой значения отображаемых показателей зависят от выбранных элементов и фильтров.




![mosedu-dinamic](mosedu-dinamic.gif)

_Рис 1. Пример простейшего взаимодействия виджетов_

Срез представляет собой изменяемый "по измерениям" набор данных - исходных или результатов аналитических вычислений; характеризуется выходными полями/столбцами, перечнем поддерживаемых измерений и набором параметров со значениями по-умолчанию; описывается относительно элегантным запросом в визуальном редакторе, поддерживающем фильтрацию, сортировку, группировку/агрегацию, пересечения (JOIN), объединения (UNION), рекурсию и другие манипуляции.



![mosedu-slice](/home/ubuntu/data/keshif-demo/thirdparty/jsbeans/plugins/datacube/docs/Article - not OLAP/mosedu-slice.png)

_Рис 2. Пример запроса у среза_



Срез поддерживает как явно заданные в выходных полях измерения, так и наследует измерения от источников запроса - это означает, что выходные данные среза могут быть изменены согласно глобальному фильтру, включающему поддерживаемые срезом измерения, значения, условия и выражения. Другми словами, результаты среза могут быть отфильтрованы не только по выходным полям, но и по внутренним полям-измерениям источников, где-то в глубине запроса, вплоть до первичных таблиц БД. Структура запроса разворачивается и изменяется системой автоматически в момент выполнения, в зависимости от актуального глобального фильтра и входных параметров, протаскивая их вглубь запроса согласно модели куба, объявленных измерений и срезов.



![mosedu-filter](/home/ubuntu/data/keshif-demo/thirdparty/jsbeans/plugins/datacube/docs/Article - not OLAP/mosedu-filter.png)

_Рис 3. Пример глобального фильтра на дашборде_



![mosedu-filter-json](/home/ubuntu/data/keshif-demo/thirdparty/jsbeans/plugins/datacube/docs/Article - not OLAP/mosedu-filter-json.png)

_Рис 4. Пример JSON глобального фильтра_



![mosedu-filter-sql](/home/ubuntu/data/keshif-demo/thirdparty/jsbeans/plugins/datacube/docs/Article - not OLAP/mosedu-filter-sql.png)

_Рис 5. Пример финального SQL запроса со встроенным фильтром_



## Когда источники разные

Как правило, все просто и понятно, когда приходится работать с единственным хранилищем данных. Когда их несколько и они принципиально разные - приходится применять разные трюки под каждую конкретную задачу. И всегда хочется иметь универсальное решение, которое бы подходило всегда, желательно "из коробки", как максимум с небольшими доработками. Для этого напрашивается еще одна абстракция - над хранилищами данных, во-первых, реализующая согласование форматов и языков запросов, во-вторых, обеспечивающая взаимозависимость данных, хотя бы на уровне дополнительных условий фильтрации в запросах к одному источнику по значениям из другого.

Для этого мы разработали универсальный язык запросов, подходящий и для представления виртуальной модели данных куба, и для работы с условно-произвольными хранилищами засчет автоматического преобразования запроса к нужному формату и языку. По удачному стечению обстоятельств, язык запросов, изначально предназначенный для простого маппирования и фильтрации данных из разных источников, с легкостью разросся в полноценный язык поиска и обработки данных, позволяющий строить вычислительные конструкции от самых простых до сложных в несколько страниц и множеством подзапросов.



<<Схема Query -> Engine -> (SQL+JDBC (PostgreSQL, ClickHouse, H2), Mongodb, HTTP Rest API) >>



Условно все источники можно разделить на три типа:

1. файлы с данными, требующие загрузки в систему;
2. базы данных, поддерживающие полноценную обработку данных и другие операции;
3. хранилища, поддерживающие только извлечение данных с фильтрацией или без.

С первым типом все однозначно - в системе интегрирован модуль импорта, который парсит различные входные форматы и погружает результаты в хранилище. Второй тип - самодостаточные базы данных, для работы с которыми требуется лишь транслировать исходный запрос к нужному формату и языку запроса. Третий же тип требует как минимум пост-обработки данных. И все типы при одновременном использовании так же чаще всего требуют пост-обработки, пересечения, объединения, и часто только в конце выполняется агрегация и финальные вычисления. 

_Самый простой пример, когда полностекстовый поиск выполняется в одной БД, а на выходе надо получить агрегацию показателей, сохраненных в другой БД на другом сервере._

Для реализации работы такой схемы в нашей системе реализован не хитрый алгоритм, при котором один исходный запрос одновременно подготавливается несколькими обработчиками, каждый из которых может либо отказаться от выполнения запроса при его несовместимости, либо вернуть итератор с данными, либо преобразовать запрос и инициировать работу следующей цепочки подготовки запроса другим движком. В конечном итоге для одного запроса мы получаем от одного до нескольких ленивых итераторов, формирующих один и тот же результат, но разными способами, из которых выбирается лучший (по различным критериям, определенным разработчиком в конфигурации). 

Для формирования такой цепочки подготовки запроса оказалось достаточным всего три типа конфигурируемых обработчиков:

1. трансформер, выполняющий предварительную трансформацию и оптимизацию запроса;
2. транслятор, выполняющий преобразование запроса к языку запросов целевой БД и формирующий итератор с данными;
3. внутренний интерпретатор - движок, выполняющий обработку данных, полученных напрямую из источников (на базе embedded H2).



<<Нарисовать бы схему подготовки запроса Assembly->prepare->(SQL,Mongo,Interpretator)>>



Схема интеграции данных на уровне внутреннего интерпретатора на первый взгляд кажется вычислительно тяжелой, и это правда, если работать приходится с большими объемами входных данных и необходимостью производить вычисления уже после пересечений и объединений наборов из внешних источников. Но т.к. одновременно запрос выполняется несколькими обработчиками, то интерпретатор используется только в крайних случаях, когда источники "из коробки" не поддерживают запрос целиком и его не удается разбить на части.  Так же эта проблема в рамках описанной выше парадигмы частично решается еще одним способом.

Если целевая БД поддерживает подключение внешних источников, то становится возможным создания обратного замыкания, при котором БД подключается к API системы для получения небольших оъемов данных из системы, например для фильтрации больших "на месте". Такая интеграция является прозрачной для пользователя - модель куба не меняется, а все операции выполняются системой автоматически.



<<Схема-кольцо Qubisio -(запрос)-> DB -(подзапрос)-> Qubisio -(промеж.данные)-> DB -(результат)-> Qubisio>>



<<Пример запроса к двум разным БД через внутренний интерпретатор>>



<<Пример интеграции с Clickhouse в качестве целевой БД>>









------

## 3. Общее представление о запросах

Запрос представляет собой JSON объект с определенной структурой, описывающей преобразования данных из одного или несколькх источников.

Запрос описывает:
- выходные поля и выражения их формирования или вычисления;
- условия фильтрации выходных данных или данных из источников;
- идентификаторы группы для агрегации данных;
- условия сортировки, смежения и ограничения результатов.

Запрос может состоять из:
- собственно тела запроса с выражениями, функциями, операторами, полями, константами и параметрами;
- вложенные именованные запросы;
- прямых источников, указыннх в $from/$join/$union;
- подзапросов-выражений, формирующих набор или одну строку с единственным выходным полем, значение которого используется как результат выражения с запросом.

Запрос включает от одного до нескольких источников:

- $cube - абстрактный источник-куб, реальный срез-источник подбирается системой автоматически в зависимости от используемых в запросе полей и измерений в глобальном фильтре (такой источник как правило используется для финальных аналитических вычислений);
- $from:slice - источники срезы (на входе используются данные из другого среза, с учетом параметров и условий глобальной фильтрации по измерениям);
- $from:view - источники именованные запросы (запрос определенный локально в текущем запросе;
- $from:{} - запрос-однострочник с одним выходным объектом, поля которого формируются подзапросами;
- $from:{query} - источник в форме запроса;
- $union: [...] - операция упорядоченного объединения результатов из нескольких источников (друг за другом);
- $join: {...} - операция пересечения "по условию" данных из двух источников (поддерживаются INNER/LEFT/RIGHT/FULL JOIN);
- $recursive: {...} - рекурсивный обход источника;
- $provider:provider - источник исходных данных, представляющий таблицу или коллекцию БД.

## 4. Запросы к кубу и запросы к срезу

Если источником запроса является куб, тогда система выполняет автоматический выбор конкретного источника из срезов данного куба по следующим критериям в следующем порядке:

1. срез должен иметь в качестве выходных полей все поля, используемые в данном запросе;
2. срез поддерживает максимальное число измерений, используемых в глобальном фильтре;
3. срез имеет минимальную оценку времени выполнения (или вес по некоторой магической функции оценки структуры запроса).

Если источником является срез, тогда система может автоматически заменить его на другой связанный если:

1. срез связан с исходным отношением взаимозаменяемости (задается пользователем или автоматически системой);
2. срез имеет как минимум все используемые поля исходного среза;
3. срез поддерживает не меньше измерений, используемых в глобальном фильтре, чем исходный;
4. срез имеет оценку времени выполнения меньше исходного.

## 4. Запросы к внешним источникам и интеграция разных БД

Система поддерживает возможность использования различных типов и экзепляров БД в одном срезе/запросе.

В зависимости от исходных источников, типов БД, системой автоматически будет использован подходящий движок запросов, поддерживающий используемые в запросе конструкции.
Запрос может быть выполнен как целиком в одной БД, так и с использованием внутреннего интерпретатора запросов. В первом случае основная БД во время выполнения запроса будет автоматически подключаться к датакубу для получения дополнительной выборки. Во втором случае исходные данные целиком копируются в памяти системы с последующей их обработкой.

Если запрос содержит внешние источники крайне рекомендуется контролировать размер выборки (число и размер объектов) в связи с необходимостью ее копирования во время выполнения запроса. Управление ограничениями удаленных запросов можно выполнить:
- $offset + $limit в самом запросе к удаленному источнику;
- в конфигурации опция `datacube.query.engine.loopbackQuery.limit` - число строк в результирующей выборке;
- для ClickHouse: в конфигурации опция `datacube.query.engine.loopbackQuery.clickhouse.api.maxsize` - число байт в результирующей выборке.


## 5. Движок запросов

### 5.1. Общие принципы

Движок запросов представляет собой цепочку обработки запроса с целью получения результирующей выборки.

Цепочка обработки состоит из обработяиков:
- трансформаций - многоступенчатая модификация и оптимизация запроса, подготовка к трансляции под определенный тип БД;
- трансляторов - трансляция запроса к исходным Базам данных на соответствущем языке.

Цепочка/граф выполнения запроса описывается в конфигурации, в секции `datacube.query.engines`, где каждая запись описывает один элемент цепочки "обработчик" и его конфигурацию.
Каждый обработчик может быть запущен как синхронно, так и параллельно (задается опцией async=true/false, по-умолчанию синхронно).

Конфигурация обработчика состоит из:
- поля jsb - задает имя бина с реализацией обработчика;
- поля конфигурации самого обработчика.

Главный/первый/стартовый обработчик, который используется по-умолчаниб для всех запросов, задается в конфиграциии, в опции `datacube.query.engine.start`.
Так же стартовый обработчик может быть задан при запуске запроса опцией `startEngine`.
Каждый обработчик в цепочке либо возвращает результат в виде итератора или ошибки, либо запускает другие обработчики.

Типы обработчиков (бины):
- `DataCube.Query.Engine.TransformEngine` - блок трансформации, последовательно выполяет несколько трансформаций, заданных в `transformers`;
- `DataCube.Query.Engine.H2Interpreter.H2InterpreterEngine` - внутренний движок-интерпретатор запросов
- `DataCube.Query.Engine.SQL.SQLTranslatorEngine` - транслятор запроса в язык SQL, вендор грамматики задается в `vendor`;
- `DataCube.Query.Engine.Mongo.MongoTranslatorEngine` - транслятор запроса к MongoDb с aggregate pipeline.

### 5.2. Внутренний движок-интерпретатор запросов

Внутренний движок-интерпретатор запросов используется, когда исходные источники (базы данных) не поддерживают выполнение запроса или отдельные его части, функции-операторы. Интерпретатор извлекает данные из исходных источников целиком, или усеченную/измененную выборку, используя подзапросы, после чего выполняет запрос в памяти системы.

### 5.3. Выбор итератора при нескольких вариантах выполнения запроса

По мере выполненяи запроса обработчиками может быть сформировано один или несколько итераторов одинаковых по результатам (выходным данным), но разных по способы выполнения. Например, один и тот же запрос может быть выполнен как самой БД, так и с использованием внутреннего интерпретатора; другой пример - оптимизации запроса, когда оптимизатор трансформирует запрос несколькими способами.

В конечном итоге, по завершению работы всех обработчиков, производится выбор наилучшего итератора.
В конфигурации за это отвечает секция `datacube.query.engine.iteratorSelector`.

Базовый бин, осуществляющий выбор итератора `DataCube.Query.Engine.IteratorSelector` позволяет выбрать одну из следующих стратегий выбора:
- `method = selectFirst`             - выбирает итератор первый по порядку;
- `method = selectRandom`            - каждый раз выбирает произвольный итератор;
- `method = selectBestEstimationTime`- выбирает согласно внутренней оценочной функции;
- `method = selectExecutedFirst`     - выбирает итератор, который первый вернет результат (запускаются все варианты и ожидается первый элемент результирующей выборки);
- `method = selectByEnginePriority`  - выбирает итератор по обработчику и таблице приоритетов (опция`selectByEnginePriority_defaultPriority` задает приоритет по-умолчаниюб, опция `selectByEnginePriority_selectByEnginePriority` - таблицу приоритетов);
- `method = selectVendorsOrder`      - выбирает по приоритету типа БД (вендору; порядок/приоритет задается опцией `selectVendorsOrder_vendorsOrder`).

### 5.4. Работа анализатора - $analyze:true


## 6. ...

## 7. Язык запросов

### 7.1 Структура

Общая схема любого запроса:
<pre>
{
    $select:       - задает выходные поля

    $filter:       - опционально: задает условия фильтрации по полями источников
    $postFilter:   - опционально: задает условия фильтрации по выходным полям
    $globalFilter: - опционально: задает условия глобальной фильтрации по измерениям
    
    $distinct:     - опционально: указывает на необходимость отфильтровать дубли
    $groupBy:      - опционально: задает идентификатор группы
    $sort:         - опционально: задает условия сортировки
    
    $offset:       - опционально: пропуск результатов
    $limit:        - опционально: ограничение результата
    
    $from/$join/$union/$recursive/$provider/$cube: - источник текущего запроса
    
    $context:      - опционально: задает имя контекста текущего запроса (связан с полями источников данного запроса)
    
    $params:       - опционально: определение параметров и значений по-умолчанию
    
    $views:        - опционально: локальные именованные запросы
}
</pre>


Пример запроса:
```
{
    $select: {
        "Код отрасли": {$group: {$toInt: "Код отрасли"}},
        "Число показателей отрасли": {$sum:1},
        "Сумма показателей отрасли": {$sum: {$toDouble: "Значение"}},
        "Число отраслей": {$gcount: {$distinct: "Код отрасли"}},
        "Максимальная сумма показателей отрасли": {$grmaxsum: {$toDouble: "Значение"}},
    },
    $postFilter: {
        "Сумма показателей" : {$gt: {$const:0}}
    },
    $from: "source_slice"
}
```

### 7.2 Определение выходных полей - $select

### 7.3 Параметры, определение и значения по-умолчанию - $params

Задается в запросе, когда необходимо определить используемые в текущем запросе или во внутренних запросах параметров. Так же может использоваться для переопределения значения по умолчанию параметра с таким же названием, определенного и использованного во внутренних запросах и срезах.

Имя параметра всегда задается в формате `"${имя параметра}"` и при определениии и при использовании.

Общая схема выражения определения параметров запроса:
```
$params: {
    "${имя параметра}": {
        $type:              - задает тип параметра
        $nativeType:        - задает тип параметра в формате БД
        $defaultValue:      - задает значение по-умолчанию
    },
}
```

Пример запроса:
```
{
    $params: {
        "${val1}": {
            $type: 'string',
            $defaultValue: {$const: '0.00'}
        },
        "${val2}": {
            $type: 'integer',
            $defaultValue: {$const: 0}
        }
    },
    $select: {
        "Код отрасли": {$group: {$toInt: "Код отрасли"}},
        "Сумма показателей отрасли": {$sum: {$toDouble: "Значение"}},
        "Максимальная сумма показателей отрасли": {$grmaxsum: {$toDouble: "Значение"}},
    },
    $filter: {
        $ne: [
            {$field: "Код отрасли"},
            "${val1}"
        ]
    },
    $from: "source_slice_with_param_${val2}"
}
```


### 7.4 Фильтрация по полям источника - $filter

### 7.5 Фильтрация по выходным полям - $postFilter

### 7.6 Глобальная фильтрация по измерениям - $globalFilter

### 7.7. Группировка и агрегация
#### 7.7.1. Функция определения идентификатора группы - $group
#### 7.7.2. Функции агрегации
#### 7.7.3. Удаление дублей - $distinct
#### 7.7.4. Прямое определение идентификатора группы - $groupBy
#### 7.7.5. Функции глобальной агрегации - $g*
#### 7.7.6. Функции глобальной агрегации над группами - $gr*

### 7.8. Сортировка - $sort

### 7.9. Фильтрация дублей - $distinct:true

### 7.10. Смещение и ограничение результатов - $limit, $offset

### 7.11. Глобальные подзапросы-выражения

### 7.12. Связанные подзапросы-выражения

### 7.13. Пересечение - $join

### 7.14. Объединение - $union

### 7.15. Рекурсия - $recursive

### 7.16. Встроенные и внешние типы данных - $type, $nativeType

### 7.17. Работа со строками

### 7.18. Математические операторы

### 7.19. Дата и время

### 7.20. Преобразование типов - $to*

### 7.21. Поля единственного источника - $field

### 7.22. Поля указанного источника - $field, $sourceContext

### 7.23. Внешние поля контекста родительского запроса - $field, $context

### 7.24. Константы - $const

