# Виртуальный куб Cubisio - вместо OLAP


##  Абстрактно

_Когда делаешь наоборот и получаешь то же ..._

Имея задачу аналитической (вычислительной/агрегирующей) обработки данных приходится искать копромисс между отзывчивостью, скоростью и удобством. 

Одни системы хорошо индексируют и находят, другие умеют быстро рассчитывать и агрегировать данные, третьи просты. Где-то приходится организовывать предварительную загрузку и индексирование данных со всеми сопутствующими трудностями, а где-то пользователю предоставляется абстракция его модели исходных и агрегированных данных поверх встроенных или внешних физических хранилищ и баз данных, используемых непосредственно во время вычислений. В любом случае, пользователь, от программиста до аналитика, должен проделать относительно большую работу, начиная с подготовки сырых данных и составления запросов, модели вычислений, заканчивая визуальным оформлением результата на виджетах, конечно же "Sexy" - красивых, отзывчивых и понятных, - иначе вся проделанная работа пойдет насмарку. И часто, как назло, пройдя через муки выбора решения, мы замечаем, как простая и понятная на первый взгляд задача вырастает в жуткого монстра, с которым имеющимися средствами бороться бесполезно, и надо срочно что-то изобретать - велосипед, но "с блэкджеком и шлюхами". Наш велосипед поехал, даже неплохо объезжает кочки и справляется с препятствиями, о которых раньше можно было только гадать. 

_Простая задача должна решаться просто, а сложная - тоже просто, но дольше ..._

Начиная создавать систему малыми силами, мы пошли от простого к сложному. Создавая конструктор, мы были внутренне убеждены, что мы хорошо понимаем цель системы, борясь одновременно с желанием не делать лишнего и противоположным желанием автоматизировать всё и вся, для всего создавая фреймворк. Тем более, что один замечательный фреймворк был уже готов и даже обкатан в продакшене (**jsBeans** - наша клиент-серверная платформа, которая очень хорошо вписывается в лежащие перед нами задачи). Итак, мы приступили к разработке очередной системы обработки данных, которая выросла и сейчас представляет собой одновременно и самодостаточный продукт - конструктор, и платформу для разработки целого класса систем обработки данных - **Сubisio**. 

Ниже будет описана одна сторона оригинального внутреннего устройства этой системы - вычислительная обработка для интерактивной визуализации данных. 

## Куб, срез, измерение

Основная задача - имея наборы несвязанных данных, включая разнородные внешние базы данных и файлы, сформировать многомерную модель из связанных между собой элементов исходных данных и результатов их аналитической обработки для визуализации на динамических дашбордах и взаимосвязанных виджетах.




![mosedu-dashboard](mosedu-dashboard.png)_Рис 1. Пример дашборда_

Такая модель в нашей системе называется "Куб" и буквально представляет собой абстрактную коллекцию изменяемых наборов данных, называемых "Срез", связанных между собой общими выходными (отображаемыми) полями/столбцами или внутренними полями, называемыми "Измерения" и используемыми для фильтрации и связывания срезов между собой. 




![mosedu-cube](mosedu-cube.png)

_Рис 2. Редактор модели данных куба_

Если выходное поле среза одновременно является измерением в другом срезе (имеет такое же название), то значения этого поля воспринимаются системой как "факты" (если бы мы говорили про OLAP), заданные в форме глобального фильтра, изменяющего исходные наборы данных во время вычислений и агрегации.  Как следствие возникает динамика взаимодействия виджетов, при которой значения отображаемых показателей зависят от выбранных элементов и фильтров.




![mosedu-dinamic](mosedu-dinamic.gif)

_Рис 3. Пример простейшего взаимодействия виджетов_

Срез представляет собой изменяемый "по измерениям" набор данных - исходных или результатов аналитических вычислений; характеризуется выходными полями/столбцами, перечнем поддерживаемых измерений и набором параметров со значениями по-умолчанию; описывается относительно элегантным запросом в визуальном редакторе, поддерживающем фильтрацию, сортировку, группировку/агрегацию, пересечения (JOIN), объединения (UNION), рекурсию и другие манипуляции.



![mosedu-slice](mosedu-slice.png)

_Рис 4. Редактор запроса у среза_



Срез поддерживает как явно заданные в выходных полях измерения, так и наследует измерения от источников запроса - это означает, что выходные данные среза могут быть изменены согласно глобальному фильтру, включающему поддерживаемые срезом измерения, значения, условия и выражения. Другми словами, результаты среза могут быть отфильтрованы не только по выходным полям, но и по внутренним полям-измерениям источников, где-то в глубине запроса, вплоть до первичных таблиц БД. Структура запроса разворачивается и изменяется системой автоматически в момент выполнения, в зависимости от актуального глобального фильтра и входных параметров, протаскивая их вглубь запроса согласно модели куба, объявленных измерений и срезов.



![mosedu-filter](mosedu-filter.png)

_Рис 5. Глобальный фильтр на дашборде_



![mosedu-filter-json](mosedu-filter-json.png)

_Рис 6. Глобальный фильтр в виде JSON_



![mosedu-filter-sql](mosedu-filter-sql.png)

_Рис 7. Финальный SQL запрос со встроенным фильтром_



## Когда источники разные

Как правило, все просто и понятно, когда приходится работать с единственным хранилищем данных. Когда их несколько и они принципиально разные - приходится применять разные трюки под каждую конкретную задачу. И всегда хочется иметь универсальное решение, которое бы подходило всегда, желательно "из коробки", как максимум с небольшими доработками. Для этого напрашивается еще одна абстракция - над хранилищами данных, во-первых, реализующая согласование форматов и языков запросов, во-вторых, обеспечивающая взаимозависимость данных, хотя бы на уровне дополнительных условий фильтрации в запросах к одному источнику по значениям из другого.

Для этого мы разработали универсальный язык запросов, подходящий и для представления виртуальной модели данных куба, и для работы с условно-произвольными хранилищами засчет автоматического преобразования запроса к нужному формату и языку. По удачному стечению обстоятельств, язык запросов, изначально предназначенный для простого маппирования и фильтрации данных из разных источников, с легкостью разросся в полноценный язык поиска и обработки данных, позволяющий строить вычислительные конструкции от самых простых до сложных в несколько страниц и множеством подзапросов.



<<Схема Query -> Engine -> (SQL+JDBC (PostgreSQL, ClickHouse, H2), Mongodb, HTTP Rest API) >>



Условно все источники можно разделить на три типа:

1. файлы с данными, требующие загрузки в систему;
2. базы данных, поддерживающие полноценную обработку данных и другие операции;
3. хранилища, поддерживающие только извлечение данных с фильтрацией или без.

С первым типом все однозначно - в системе интегрирован модуль импорта, который парсит различные входные форматы и погружает результаты в хранилище. Для импорта также разработан специальный конструктор, о котором стоит рассказать отдельно. Второй тип - самодостаточные базы данных, для работы с которыми требуется лишь транслировать исходный запрос к нужному формату и языку запроса, диалекту. Третий же тип требует как минимум пост-обработки данных. И все типы при одновременном использовании также могут потребовать пост-обработки, пересечения, объединения, и когда в конце выполняется агрегация и финальные вычисления. 

_Самый простой пример, когда полнотекстовый поиск выполняется в одной БД, а на выходе надо получить агрегацию показателей, сохраненных в другой БД на другом сервере._

Для реализации работы такой схемы в нашей системе реализован нехитрый алгоритм, при котором один исходный запрос одновременно подготавливается несколькими обработчиками, каждый из которых может либо отказаться от выполнения запроса при его несовместимости, либо вернуть итератор с данными, либо преобразовать запрос и инициировать работу следующей цепочки подготовки запроса другим движком. В конечном итоге для одного запроса мы получаем от одного до нескольких ленивых итераторов, формирующих один и тот же результат, но разными способами, из которых выбирается лучший (по различным критериям, определенным разработчиком в конфигурации). 

Для формирования такой цепочки подготовки запроса оказалось достаточным всего три типа конфигурируемых обработчиков:

1. трансформер, выполняющий предварительную трансформацию и оптимизацию запроса (трансформер работает по принципу pipeline, перечень операций на каждом шаге конфигурируется);
2. транслятор, выполняющий преобразование запроса к языку запросов и диалекту целевой БД, в результате формирующий итератор с данными;
3. внутренний интерпретатор - движок, выполняющий обработку данных, полученных напрямую из источников, результирующий итератор формируется поверх embedded H2 (используются table functions).



<<Нарисовать бы схему подготовки запроса Assembly->prepare->(SQL,Mongo,Interpretator)>>



Схема интеграции данных на уровне внутреннего интерпретатора на первый взгляд кажется вычислительно тяжелой, и это правда, если приходится работать с большими объемами входных данных и необходимостью производить вычисления уже после пересечений и объединений наборов из внешних источников. Но, во-первых, одновременно запрос выполняется несколькими обработчиками, т.е. интерпретатор используется только в крайних случаях, когда источники "из коробки" не поддерживают запрос целиком и его не удается разбить на части. Во-вторых, эта проблема в рамках описанной выше парадигмы частично нивелируется еще одним способом.

Если целевая БД поддерживает подключение внешних источников, то становится возможным создание обратного замыкания, при котором БД подключается к API системы для получения небольших оъемов данных из системы, например для фильтрации больших "на месте". Такая интеграция является прозрачной для пользователя - модель куба не меняется, а все операции выполняются системой автоматически. 



<<Схема-кольцо Cubisio -(запрос)-> DB -(подзапрос)-> Cubisio -(промеж.данные)-> DB -(результат)-> Qubisio>>



<<Пример запроса к двум разным БД через внутренний интерпретатор>>



<<Пример интеграции с Clickhouse в качестве целевой БД>>



## Почему так?

_Никогда такого не было, и вот опять..._

Наша первичная уверенность в выборе пути или концепции развития системы оказалась обусловлена не сколько внутренней самоуверенностью, программистским опытом, сколько попаданием в ожидаемый и свершившийся факт...

Первичных наборов данных заведомо ожидалось очень много. На первых парах их было мало, предметные области были конкретизированы, казалось - зачем такие мучения? Хотелось получить результат быстро - особенно, когда быстрое решение лежит на поверхости, а правильное требует усидчивости и взвешенных решений, соблюдения изначальной установки.

Дашборды должны строиться быстро, даже если новая предметная область и аналитические потребности сильно отличаются от предыдущих. Заведомо не угадаешь и половины будущих требований. Доработка библиотеки компонент, аналитических алгоритмов, подключение новых типов источников - неотемлемая часть адаптации системы. Другими словами, аналитики строят запросы и дашборды, а программисты оперативно реализуют для них новые потребности. И мы, как программисты, стремились упростить работу себе в будущем, стараясь не навредить юзабилити.

 И система сразу создавалась универсальной и адаптивной - мы строили "конструктор конструктором", разрабатывая фреймворк поверх фреймворка, ранее созданного с похожей но еще более общей целью. 



**Cubisio** - ...

**jsBeans** - ..



_В зависимости от реакции и предпочтений читателя, в следующих статьях раскроем конструируемую подсистему визуализации, аналитические процессы, язык запросов, импорт данных и другие стороны некоторых решений нашей команды._

